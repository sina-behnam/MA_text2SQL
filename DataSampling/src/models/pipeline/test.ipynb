{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949c39d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from text2sql_pipeline import Text2SQLPipeline\n",
    "\n",
    "# Dataset paths - configure these for your environment\n",
    "BIRD_DATASET_PATH = '/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/DataSampling/src/src_data/bird_subset/stratified_output'\n",
    "SPIDER_DATASET_PATH = '/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/DataSampling/src/src_data/spider_subset/spider_stratified_output_200'\n",
    "API_KEY = 'db07a16311d7f554af4d89c69fb2bf55eecb525746bb96be93f2167b2fffdf88'\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158d49e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_summary_from_directory(base_dir):\n",
    "    \"\"\"\n",
    "    Generate evaluation summary by reading enriched JSON files from directory.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing model-specific subdirectories with enriched JSON files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics for each model\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Find all model directories\n",
    "    model_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    \n",
    "    for model_dir in model_dirs:\n",
    "        model_path = os.path.join(base_dir, model_dir)\n",
    "        \n",
    "        # Get all JSON files in this model directory\n",
    "        json_files = glob.glob(os.path.join(model_path, '*.json'))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(f\"No JSON files found in {model_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Metrics to calculate\n",
    "        num_evaluated = len(json_files)\n",
    "        has_prediction = 0\n",
    "        execution_correct = 0\n",
    "        exact_match = 0\n",
    "        semantic_equivalent = 0\n",
    "        model_info = None\n",
    "        \n",
    "        # Process each JSON file\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Extract inference results\n",
    "                if 'inference_results' in data:\n",
    "                    inference = data['inference_results']\n",
    "                    \n",
    "                    # Save model info if not already set\n",
    "                    if model_info is None and 'model' in inference:\n",
    "                        model_info = inference['model']\n",
    "                    \n",
    "                    # Count metrics\n",
    "                    if inference.get('has_prediction', False):\n",
    "                        has_prediction += 1\n",
    "                        \n",
    "                        pred_output = inference.get('predicted_output', {})\n",
    "                        if pred_output.get('execution_correct', False):\n",
    "                            execution_correct += 1\n",
    "                        if pred_output.get('exact_match', False):\n",
    "                            exact_match += 1\n",
    "                        if pred_output.get('semantic_equivalent', False):\n",
    "                            semantic_equivalent += 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'num_evaluated': num_evaluated,\n",
    "            'num_with_prediction': has_prediction,\n",
    "            'prediction_rate': has_prediction / num_evaluated if num_evaluated > 0 else 0,\n",
    "            'execution_accuracy': execution_correct / has_prediction if has_prediction > 0 else 0,\n",
    "            'exact_match_accuracy': exact_match / has_prediction if has_prediction > 0 else 0,\n",
    "            'semantic_equivalent_accuracy': semantic_equivalent / has_prediction if has_prediction > 0 else 0,\n",
    "            'model': model_info or {'model_name': model_dir}\n",
    "        }\n",
    "        \n",
    "        # Get the full model name from the model info\n",
    "        model_name = model_info['model_name'] if model_info and 'model_name' in model_info else model_dir\n",
    "        \n",
    "        # Add to summary\n",
    "        summary[model_name] = metrics\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"\\nMetrics for model {model_name}:\")\n",
    "        print(f\"Total evaluated: {metrics['num_evaluated']}\")\n",
    "        print(f\"Prediction rate: {metrics['prediction_rate']:.2f}\")\n",
    "        print(f\"Execution accuracy: {metrics['execution_accuracy']:.2f}\")\n",
    "        print(f\"Exact match accuracy: {metrics['exact_match_accuracy']:.2f}\")\n",
    "        print(f\"Semantic equivalence accuracy: {metrics['semantic_equivalent_accuracy']:.2f}\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da66f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up output directories for updated JSON files\n",
    "OUTPUT_BASE_DIR = '/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/output/pipeline/enriched_output'\n",
    "os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Define model configurations for testing\n",
    "model_configs = [\n",
    "    # API-based models\n",
    "    # {\n",
    "    #     \"type\": \"together_ai\",\n",
    "    #     \"name\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free\",\n",
    "    #     \"api_key\": API_KEY\n",
    "    # },\n",
    "    # Local models - uncomment and configure as needed\n",
    "    {\n",
    "        \"type\": \"local\",\n",
    "        \"name\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        \"device\": \"auto\",\n",
    "        \"max_new_tokens\": 512\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"local\",\n",
    "    #     \"name\": \"TheBloke/Llama-2-7B-Chat-GGUF\",\n",
    "    #     \"device\": \"cpu\",\n",
    "    #     \"max_new_tokens\": 512\n",
    "    # }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54e6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating local model: mistralai/Mistral-7B-Instruct-v0.1\n",
      "Total data points: 521\n",
      "Bird data points: 200\n",
      "Spider data points: 321\n",
      "Training data points: 416\n",
      "Testing data points: 105\n",
      "Loading model mistralai/Mistral-7B-Instruct-v0.1 on cpu...\n",
      "Error processing model mistralai/Mistral-7B-Instruct-v0.1: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like mistralai/Mistral-7B-Instruct-v0.1 is not the path to a directory containing a file named config.json.\n",
      "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1484, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1401, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 285, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 309, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py\", line 473, in hf_raise_for_status\n",
      "    raise _format(HfHubHTTPError, message, response) from e\n",
      "huggingface_hub.errors.HfHubHTTPError: (Request ID: Root=1-681b1026-380bb57f52a5b06f4d2b7472;9a1ceee4-2f03-436b-aeb7-cd190de149da)\n",
      "\n",
      "403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\n",
      "Cannot access content at: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/config.json.\n",
      "Make sure your token has the correct permissions.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/utils/hub.py\", line 342, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 961, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1068, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1599, in _raise_on_head_call_error\n",
      "    raise LocalEntryNotFoundError(\n",
      "huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/kh/4c5yssv50_50b3lvjhmzt19m0000gn/T/ipykernel_76100/31883151.py\", line 17, in <module>\n",
      "    pipeline = Text2SQLPipeline(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/DataSampling/src/models/pipeline/text2sql_pipeline.py\", line 64, in __init__\n",
      "    self._init_model_provider()\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/DataSampling/src/models/pipeline/text2sql_pipeline.py\", line 79, in _init_model_provider\n",
      "    self.model_provider = LocalHuggingFaceProvider(model_name, device, max_new_tokens)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/DataSampling/src/models/pipeline/models.py\", line 144, in __init__\n",
      "    self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py\", line 901, in from_pretrained\n",
      "    config = AutoConfig.from_pretrained(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 1075, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/configuration_utils.py\", line 594, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/configuration_utils.py\", line 653, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/Users/sinabehnam/Desktop/Projects/Polito/Thesis/MA_text2SQL/venv/lib/python3.12/site-packages/transformers/utils/hub.py\", line 385, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like mistralai/Mistral-7B-Instruct-v0.1 is not the path to a directory containing a file named config.json.\n",
      "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for model_config in model_configs:\n",
    "    model_name = model_config[\"name\"]\n",
    "    model_type = model_config[\"type\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nEvaluating {model_type} model: {model_name}\")\n",
    "        \n",
    "        # Create model-specific output directory\n",
    "        # Use the last part of the model name for the directory name\n",
    "        model_dir_name = model_name.split('/')[-1]\n",
    "        model_output_dir = os.path.join(OUTPUT_BASE_DIR, model_dir_name)\n",
    "        os.makedirs(model_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize the pipeline with this model configuration\n",
    "        pipeline = Text2SQLPipeline(\n",
    "            bird_path=BIRD_DATASET_PATH,\n",
    "            spider_path=SPIDER_DATASET_PATH,\n",
    "            model_config=model_config\n",
    "        )\n",
    "        \n",
    "        # Run the pipeline\n",
    "        results = pipeline.run_pipeline(\n",
    "            num_samples=10,\n",
    "            save_updated_files=True,\n",
    "            output_dir=model_output_dir\n",
    "        )\n",
    "        \n",
    "        # Store summary metrics (without detailed results)\n",
    "        summary_metrics = {\n",
    "            'num_evaluated': results['num_evaluated'],\n",
    "            'num_with_prediction': results['num_with_prediction'],\n",
    "            'prediction_rate': results['prediction_rate'],\n",
    "            'execution_accuracy': results['execution_accuracy'],\n",
    "            'exact_match_accuracy': results['exact_match_accuracy'],\n",
    "            'semantic_equivalent_accuracy': results.get('semantic_equivalent_accuracy', 0.0),\n",
    "            'model': results['model']\n",
    "        }\n",
    "        \n",
    "        all_results[model_name] = summary_metrics\n",
    "        \n",
    "        # Print summary metrics\n",
    "        print(\"\\nSummary Metrics:\")\n",
    "        print(f\"Total evaluated: {summary_metrics['num_evaluated']}\")\n",
    "        print(f\"Prediction rate: {summary_metrics['prediction_rate']:.2f}\")\n",
    "        print(f\"Execution accuracy: {summary_metrics['execution_accuracy']:.2f}\")\n",
    "        print(f\"Exact match accuracy: {summary_metrics['exact_match_accuracy']:.2f}\")\n",
    "        print(f\"Semantic equivalence accuracy: {summary_metrics.get('semantic_equivalent_accuracy', 0.0):.2f}\")\n",
    "        print(f\"Updated JSON files saved to: {model_output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_traceback = traceback.format_exc()\n",
    "        print(f\"Error processing model {model_name}: {str(e)}\")\n",
    "        print(f\"Traceback: {error_traceback}\")\n",
    "        \n",
    "        # Add error information to results\n",
    "        all_results[model_name] = {\n",
    "            'error': str(e),\n",
    "            'traceback': error_traceback,\n",
    "            'model': {'model_name': model_name, 'model_type': model_type}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary metrics to file with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "summary_file = os.path.join(OUTPUT_BASE_DIR, f'evaluation_summary_{timestamp}.json')\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"\\nEvaluation complete. Summary saved to '{summary_file}'\")\n",
    "print(f\"Individual JSON files with inference results saved to model-specific directories under '{OUTPUT_BASE_DIR}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary from enriched files as a verification\n",
    "print(\"\\nGenerating summary from enriched files...\")\n",
    "directory_summary = generate_evaluation_summary_from_directory(OUTPUT_BASE_DIR)\n",
    "\n",
    "# Save the directory-based summary\n",
    "summary_from_dir_file = os.path.join(OUTPUT_BASE_DIR, f'evaluation_summary_from_dir_{timestamp}.json')\n",
    "with open(summary_from_dir_file, 'w') as f:\n",
    "    json.dump(directory_summary, f, indent=2)\n",
    "\n",
    "print(f\"Summary from directory saved to '{summary_from_dir_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
